KSYLDATA:
  num_nodes: 5
  input_steps: 60  # 原 in_steps
  output_steps: 60  # 原 out_steps

  train_size: 0.7
  val_size: 0.1

  time_of_day: True
  day_of_week: True

  lr: 0.001
  weight_decay: 0.0003
  milestones: [20,30]
  lr_decay_rate: 0.1
  batch_size: 32
  max_epochs: 200
  early_stop: 30
  use_cl: False
  cl_step_size: 2500
  #clip_grad: 5

  model_args:
    num_nodes: 5
    input_steps: 60  # 原 in_steps
    output_steps: 60  # 原 out_steps
    steps_per_day: 1440
    input_dim: 1
    output_dim: 1
    input_embedding_dim: 24
    tod_embedding_dim: 24
    dow_embedding_dim: 24
    adaptive_embedding_dim: 80
    dropout_adaptive: 0.3  # 原 dropout_a

    d_conv: 4
    expand: 2
    dropout_mamba: 0.15  # 原 dropout_m
    num_mamba_layers: 1  # 原 num_layers_ma
    # MLP
    num_layers: 4
    dropout_rate: 0.1  # 原 dropout
    # Memory parameters - 更清晰的命名
    memory_slots: 10  # 原 N_m
    memory_dim: 64  # 原 D_m
    attention_slots: 10  # 原 N_k
    conv_stride: 2
    conv_kernel: 3  # 原 conv_k
    attention_dim: 4  # 原 dim_k

METRLA:
  num_nodes: 207
  input_steps: 12
  output_steps: 12

  train_size: 0.7
  val_size: 0.1

  time_of_day: True
  day_of_week: True

  lr: 0.001
  weight_decay: 0.0003
  milestones: [20,30]
  lr_decay_rate: 0.1
  batch_size: 8
  max_epochs: 200
  early_stop: 20
  use_cl: False
  cl_step_size: 2500
  #clip_grad: 5

  model_args:
    num_nodes: 207
    input_steps: 12
    output_steps: 12
    steps_per_day: 288
    input_dim: 3
    output_dim: 1
    input_embedding_dim: 12
    tod_embedding_dim: 12
    dow_embedding_dim: 12
    adaptive_embedding_dim: 12
    dropout_adaptive: 0.3

    d_conv: 8
    expand: 2
    dropout_mamba: 0.15
    num_mamba_layers: 1
    # MLP
    num_layers: 2
    dropout_rate: 0.1
    # Memory parameters
    memory_slots: 40
    memory_dim: 48
    attention_slots: 10
    conv_stride: 2
    conv_kernel: 3
    attention_dim: 4

PEMSBAY:
  num_nodes: 325
  input_steps: 12
  output_steps: 12

  train_size: 0.7
  val_size: 0.1

  time_of_day: True
  day_of_week: True

  lr: 0.001
  weight_decay: 0.0001
  milestones: [10, 30]
  lr_decay_rate: 0.1
  batch_size: 16
  max_epochs: 300
  early_stop: 20
  use_cl: False

  model_args:
    num_nodes: 325
    input_steps: 12
    output_steps: 12
    steps_per_day: 288
    input_dim: 3
    output_dim: 1
    input_embedding_dim: 36
    tod_embedding_dim: 36
    dow_embedding_dim: 36
    adaptive_embedding_dim: 12
    dropout_adaptive: 0.3

    d_state: 8
    d_conv: 4
    expand: 2
    dropout_mamba: 0.15
    num_mamba_layers: 1
    # MLP
    num_layers: 4
    dropout_rate: 0.1
    # Memory parameters
    memory_slots: 10
    memory_dim: 64
    attention_slots: 10
    conv_stride: 2
    conv_kernel: 3
    attention_dim: 4

PEMS03:
  num_nodes: 358
  input_steps: 12
  output_steps: 12

  train_size: 0.6
  val_size: 0.2

  time_of_day: True
  day_of_week: True

  lr: 0.001
  weight_decay: 0.0015
  milestones: [30, 50, 70]
  lr_decay_rate: 0.1
  batch_size: 32
  max_epochs: 1
  early_stop: 20
  use_cl: False
  cl_step_size: 2500

  model_args:
    num_nodes: 358
    input_steps: 12
    output_steps: 12
    steps_per_day: 288
    input_dim: 1
    output_dim: 1
    input_embedding_dim: 24
    tod_embedding_dim: 24
    dow_embedding_dim: 24
    adaptive_embedding_dim: 12
    dropout_adaptive: 0.35

    d_state: 2
    d_conv: 2
    expand: 2
    dropout_mamba: 0.15
    num_mamba_layers: 1
    # MLP
    num_layers: 4
    dropout_rate: 0.1
    # Memory parameters
    memory_slots: 32
    memory_dim: 24
    attention_slots: 8
    conv_stride: 2
    conv_kernel: 3
    attention_dim: 4

PEMS04:
  num_nodes: 307
  input_steps: 12
  output_steps: 12

  train_size: 0.6
  val_size: 0.2

  time_of_day: True
  day_of_week: True

  lr: 0.01
  weight_decay: 0.001
  milestones: [15, 50, 70]
  lr_decay_rate: 0.1
  batch_size: 32
  max_epochs: 1
  early_stop: 20
  use_cl: False
  cl_step_size: 2500

  model_args:
    num_nodes: 307
    input_steps: 12
    output_steps: 12
    steps_per_day: 288
    input_dim: 1
    output_dim: 1
    input_embedding_dim: 24
    tod_embedding_dim: 24
    dow_embedding_dim: 24
    adaptive_embedding_dim: 12
    dropout_adaptive: 0.35

    d_state: 6
    d_conv: 2
    expand: 2
    dropout_mamba: 0.15
    num_mamba_layers: 1
    # MLP
    num_layers: 4
    dropout_rate: 0.1
    # Memory parameters
    memory_slots: 30
    memory_dim: 24
    attention_slots: 8
    conv_stride: 2
    conv_kernel: 3
    attention_dim: 4

PEMS07:
  num_nodes: 883
  input_steps: 12
  output_steps: 12

  train_size: 0.6
  val_size: 0.2

  time_of_day: True
  day_of_week: True

  lr: 0.001
  weight_decay: 0.001
  milestones: [30, 50, 70]
  lr_decay_rate: 0.1
  batch_size: 8
  max_epochs: 1
  early_stop: 20
  use_cl: False
  cl_step_size: 2500

  model_args:
    num_nodes: 883
    input_steps: 12
    output_steps: 12
    steps_per_day: 288
    input_dim: 3
    output_dim: 1
    input_embedding_dim: 32
    tod_embedding_dim: 32
    dow_embedding_dim: 32
    adaptive_embedding_dim: 12
    dropout_adaptive: 0.35

    d_state: 2
    d_conv: 2
    expand: 2
    dropout_mamba: 0.15
    num_mamba_layers: 1
    # MLP
    num_layers: 4
    dropout_rate: 0.1
    # Memory parameters
    memory_slots: 64
    memory_dim: 24
    attention_slots: 8
    conv_stride: 2
    conv_kernel: 3
    attention_dim: 4

PEMS08:
  num_nodes: 170
  input_steps: 12
  output_steps: 12

  train_size: 0.6
  val_size: 0.2

  time_of_day: True
  day_of_week: True

  lr: 0.01
  weight_decay: 0.0015
  milestones: [15, 50, 70]
  lr_decay_rate: 0.1
  batch_size: 32
  max_epochs: 1
  early_stop: 20
  use_cl: False
  cl_step_size: 2500

  model_args:
    num_nodes: 170
    input_steps: 12
    output_steps: 12
    steps_per_day: 288
    input_dim: 1
    output_dim: 1
    input_embedding_dim: 24
    tod_embedding_dim: 24
    dow_embedding_dim: 24
    adaptive_embedding_dim: 12
    dropout_adaptive: 0.5
    # Mamba parameters
    d_state: 6
    d_conv: 2
    expand: 2
    dropout_mamba: 0.15
    num_mamba_layers: 1
    # MLP
    num_layers: 4
    dropout_rate: 0.1
    # Memory parameters
    memory_slots: 64
    memory_dim: 24
    attention_slots: 8
    conv_stride: 2
    conv_kernel: 3
    attention_dim: 4

SD:
  num_nodes: 716
  input_steps: 12
  output_steps: 12

  train_size: 0.6
  val_size: 0.2

  time_of_day: True
  day_of_week: True

  lr: 0.01
  weight_decay: 0.01
  milestones: [10, 50, 70]
  lr_decay_rate: 0.1
  batch_size: 32
  max_epochs: 100
  early_stop: 20
  use_cl: False
  cl_step_size: 2500

  model_args:
    num_nodes: 716
    input_steps: 12
    output_steps: 12
    steps_per_day: 96
    input_dim: 3
    output_dim: 1
    input_embedding_dim: 24
    tod_embedding_dim: 24
    dow_embedding_dim: 24
    adaptive_embedding_dim: 12
    dropout_adaptive: 0.35

    # Mamba parameters
    d_state: 2
    d_conv: 2
    expand: 2
    dropout_mamba: 0.15
    num_mamba_layers: 1
    # MLP
    num_layers: 4
    dropout_rate: 0.1
    # Memory parameters
    memory_slots: 40
    memory_dim: 24
    attention_slots: 8
    conv_stride: 2
    conv_kernel: 3
    attention_dim: 4

GBA:
  num_nodes: 2352
  input_steps: 12
  output_steps: 12

  train_size: 0.6
  val_size: 0.2

  time_of_day: True
  day_of_week: True

  lr: 0.001
  weight_decay: 0.005
  milestones: [30, 50, 70]
  lr_decay_rate: 0.1
  batch_size: 1
  max_epochs: 100
  early_stop: 20
  use_cl: False
  cl_step_size: 2500

  model_args:
    num_nodes: 2352
    input_steps: 12
    output_steps: 12
    steps_per_day: 96
    input_dim: 3
    output_dim: 1
    input_embedding_dim: 24
    tod_embedding_dim: 24
    dow_embedding_dim: 24
    adaptive_embedding_dim: 12
    dropout_adaptive: 0.3

    # Mamba parameters
    d_state: 8
    d_conv: 4
    expand: 2
    dropout_mamba: 0.15
    num_mamba_layers: 1
    # MLP
    num_layers: 4
    dropout_rate: 0.1
    # Memory parameters
    memory_slots: 64
    memory_dim: 84
    attention_slots: 40
    conv_stride: 2
    conv_kernel: 3
    attention_dim: 4

GLA:
  num_nodes: 3834
  input_steps: 12
  output_steps: 12

  train_size: 0.6
  val_size: 0.2

  time_of_day: True
  day_of_week: True

  lr: 0.001
  weight_decay: 0.005
  milestones: [30, 50, 70]
  lr_decay_rate: 0.1
  batch_size: 1
  max_epochs: 100
  early_stop: 20
  use_cl: False
  cl_step_size: 2500

  model_args:
    num_nodes: 3834
    input_steps: 12
    output_steps: 12
    steps_per_day: 96
    input_dim: 3
    output_dim: 1
    input_embedding_dim: 24
    tod_embedding_dim: 24
    dow_embedding_dim: 24
    adaptive_embedding_dim: 12
    dropout_adaptive: 0.5
    # Mamba parameters
    d_state: 8
    d_conv: 4
    expand: 2
    dropout_mamba: 0.15
    num_mamba_layers: 1
    # MLP
    num_layers: 4
    dropout_rate: 0.1
    # Memory parameters
    memory_slots: 64
    memory_dim: 84
    attention_slots: 40
    conv_stride: 2
    conv_kernel: 3
    attention_dim: 4
